{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df85f34-5264-439d-b466-5ed79f5d5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, os.path\n",
    "from os.path import splitext,isfile,join\n",
    "from os import listdir\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from pydicom.uid import UID, generate_uid\n",
    "import shutil\n",
    "from multiprocessing import dummy as multiprocessing\n",
    "import time\n",
    "import subprocess\n",
    "import datetime\n",
    "from datetime import date\n",
    "import sys\n",
    "import cv2\n",
    "#from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from shutil import copy\n",
    "import math\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e30044-ad8f-43bc-8b50-9d47d18fc306",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinationFolder = \"/Users/vt2113/Desktop/DICOM #2/DynamicOutput\"\n",
    "inputFolder = '/Users/vt2113/Desktop/DICOM #2/Dynamic Data#2'\n",
    "AVIFolder = '/Users/vt2113/Desktop/DICOM #2/DynamicAVI'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e1913b-7711-459b-8c40-c689ed5b5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(output):\n",
    "\n",
    "    dim1 = output.shape[0]\n",
    "    dim2 = output.shape[1]\n",
    "    \n",
    "    # Mask pixels outside of scanning sector\n",
    "    m1, m2 = np.meshgrid(np.arange(dim2), np.arange(dim1))\n",
    "    \n",
    "\n",
    "    mask = ((m1+m2)>(int(dim2/2) +int(dim2/12))) \n",
    "    # mask = m2> dim1/dim2*(-m1+int(dim2/2)) +int(dim2/10)\n",
    "    mask *=  ((m1-m2)<(int(dim2/2) -int(dim2/12)))\n",
    "    # mask *= -m2< dim1/dim2*(-m1+int(dim2/2)) -int(dim2/10)\n",
    "    \n",
    "    mask = np.reshape(mask, (dim1, dim2)).astype(np.int8)\n",
    "    maskedImage = cv2.bitwise_and(output, output, mask = mask)\n",
    "    \n",
    "    #print(maskedImage.shape)\n",
    "    \n",
    "    return maskedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "098f4f1f-b057-4df1-9004-0693409e1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVideo(fileToProcess, destinationFolder):\n",
    "\n",
    "    fileName = fileToProcess.split('/')[-1] #\\\\ if windows, / if on mac or sherlock\n",
    "                                             #hex(abs(hash(fileToProcess.split('/')[-1]))).upper()\n",
    "\n",
    "    if not os.path.exists(os.path.join(destinationFolder,fileName[:-4]+'.avi')):\n",
    "        # print(os.path.join(destinationFolder,fileName[:-4]+'.avi'))\n",
    "\n",
    "        dataset = dicom.dcmread(fileToProcess, force=True)\n",
    "        testarray = dataset.pixel_array\n",
    "        if len(testarray.shape)!=4:\n",
    "            return 0\n",
    "\n",
    "#         frame0 = testarray[0]\n",
    "#         plt.imshow(frame0[:,:,2])\n",
    "#         mean = np.mean(frame0, axis=1)[:,0]\n",
    "# #         mean = np.mean(mean, axis=1)\n",
    "# #         plt.plot(mean)\n",
    "#         try:\n",
    "#             yCrop = np.where(mean<1)[0][0]\n",
    "#             testarray = testarray[:, yCrop:, :, :]\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "        bias = int(np.abs(testarray.shape[2] - testarray.shape[1])/2)\n",
    "        if bias>0:\n",
    "            if testarray.shape[1] < testarray.shape[2]:\n",
    "                testarray = testarray[:, :, bias:-bias, :]\n",
    "            else:\n",
    "                testarray = testarray[:, bias:-bias, :, :]\n",
    "\n",
    "        # print(.shape)\n",
    "        frames,height,width,channels = testarray.shape\n",
    "\n",
    "        fps = 30\n",
    "\n",
    "        try:\n",
    "            fps = dataset[(0x18, 0x40)].value\n",
    "        except:\n",
    "            print(\"couldn't find frame rate, default to 30\")\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "        video_filename = os.path.join(destinationFolder, fileName[:-4] + '.avi')\n",
    "        out = cv2.VideoWriter(video_filename, fourcc, fps, cropSize)\n",
    "\n",
    "\n",
    "        for i in range(frames):\n",
    "\n",
    "            outputA = testarray[i,:,:,0]\n",
    "            outputA = mask(outputA)\n",
    "            outputA = outputA[int(height/10):(height - int(height/10)), int(height/10):(height - int(height/10))]\n",
    "\n",
    "#             # Resize image\n",
    "            finaloutput = cv2.resize(outputA, cropSize, interpolation = cv2.INTER_CUBIC)\n",
    "            # finaloutput = mask(output)\n",
    "\n",
    "\n",
    "            finaloutput = cv2.merge([finaloutput,finaloutput,finaloutput])\n",
    "            out.write(finaloutput)\n",
    "\n",
    "        out.release()\n",
    "\n",
    "    else:\n",
    "        print(fileName,\"hasAlreadyBeenProcessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13287c18-86ba-418d-b21d-e0afdd54b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic-OHT21-055-2.dcm hasAlreadyBeenProcessed\n",
      "Dynamic-OHT21-032.dcm hasAlreadyBeenProcessed\n",
      "Dynamic-OHT21-068-2.dcm hasAlreadyBeenProcessed\n",
      "Dynamic-OFF22-023-2.dcm hasAlreadyBeenProcessed\n",
      "couldn't find frame rate, default to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▌                                     | 11/102 [00:14<02:44,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find frame rate, default to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▌                                   | 16/102 [00:26<03:27,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find frame rate, default to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▎                               | 25/102 [00:49<03:23,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find frame rate, default to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████▌                            | 33/102 [01:10<02:57,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find frame rate, default to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▉                         | 41/102 [01:26<01:57,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find frame rate, default to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████            | 73/102 [02:57<01:05,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find frame rate, default to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|████████████████████████████████▉         | 80/102 [03:14<00:43,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find frame rate, default to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████     | 90/102 [03:35<00:18,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't find frame rate, default to 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 102/102 [04:17<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "## Convert to AVI \n",
    "cropSize = (112,112)\n",
    "onlyfiles = [f for f in listdir(inputFolder) if isfile(join(inputFolder, f))]\n",
    "# print(onlyfiles)\n",
    "for f in tqdm.tqdm(onlyfiles[1:]):\n",
    "    makeVideo(os.path.join(inputFolder,f),AVIFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0fa48a7-eae5-4f22-9a03-04f943c74d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# David Ouyang 12/5/2019\n",
    "\n",
    "# Notebook which:\n",
    "# 1. Downloads weights\n",
    "# 2. Initializes model and imports weights\n",
    "# 3. Performs test time evaluation of videos (already preprocessed with ConvertDICOMToAVI.ipynb)\n",
    "\n",
    "import re\n",
    "import os, os.path\n",
    "from os.path import splitext\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from pydicom.uid import UID, generate_uid\n",
    "import shutil\n",
    "from multiprocessing import dummy as multiprocessing\n",
    "import time\n",
    "import subprocess\n",
    "import datetime\n",
    "from datetime import date\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from shutil import copy\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import pathlib\n",
    "import tqdm\n",
    "import scipy \n",
    "import skimage\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import echonet\n",
    "\n",
    "import wget \n",
    "\n",
    "videosFolder = AVIFolder\n",
    "#DestinationForWeights = \"/Users/davidouyang/Dropbox/Echo Research/CodeBase/EchoNetDynamic-Weights\"\n",
    "DestinationForWeights = \"/Users/vt2113/DonorAI/dynamic/Weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b03ac9f-63e0-4838-821a-e8cfd8aa1f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights are at /Users/vt2113/DonorAI/dynamic/Weights\n",
      "Segmentation Weights already present\n",
      "EF Weights already present\n"
     ]
    }
   ],
   "source": [
    "# Download model weights\n",
    "\n",
    "if os.path.exists(DestinationForWeights):\n",
    "    print(\"The weights are at\", DestinationForWeights)\n",
    "else:\n",
    "    print(\"Creating folder at \", DestinationForWeights, \" to store weights\")\n",
    "    os.mkdir(DestinationForWeights)\n",
    "    \n",
    "segmentationWeightsURL = 'https://github.com/douyang/EchoNetDynamic/releases/download/v1.0.0/deeplabv3_resnet50_random.pt'\n",
    "ejectionFractionWeightsURL = 'https://github.com/douyang/EchoNetDynamic/releases/download/v1.0.0/r2plus1d_18_32_2_pretrained.pt'\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(DestinationForWeights, os.path.basename(segmentationWeightsURL))):\n",
    "    print(\"Downloading Segmentation Weights, \", segmentationWeightsURL,\" to \",os.path.join(DestinationForWeights,os.path.basename(segmentationWeightsURL)))\n",
    "    filename = wget.download(segmentationWeightsURL, out = DestinationForWeights)\n",
    "else:\n",
    "    print(\"Segmentation Weights already present\")\n",
    "    \n",
    "if not os.path.exists(os.path.join(DestinationForWeights, os.path.basename(ejectionFractionWeightsURL))):\n",
    "    print(\"Downloading EF Weights, \", ejectionFractionWeightsURL,\" to \",os.path.join(DestinationForWeights,os.path.basename(ejectionFractionWeightsURL)))\n",
    "    filename = wget.download(ejectionFractionWeightsURL, out = DestinationForWeights)\n",
    "else:\n",
    "    print(\"EF Weights already present\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107c2c1b-8e10-4e3f-8fe1-765f7f2b90f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  /Users/vt2113/DonorAI/dynamic/Weights/deeplabv3_resnet50_random\n",
      "cuda is not available, cpu weights\n"
     ]
    }
   ],
   "source": [
    "# Set up model\n",
    "model_name = 'deeplabv3_resnet50'\n",
    "pretrained = False\n",
    "model = torchvision.models.segmentation.__dict__[model_name](pretrained=pretrained, aux_loss=False)\n",
    "model.classifier[-1] = torch.nn.Conv2d(model.classifier[-1].in_channels, 1, kernel_size=model.classifier[-1].kernel_size)  # change number of outputs to 1\n",
    "\n",
    "print(\"loading weights from \", os.path.join(DestinationForWeights, \"deeplabv3_resnet50_random\"))\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is available, original weights\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    checkpoint = torch.load(os.path.join(DestinationForWeights, os.path.basename(segmentationWeightsURL)))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else:\n",
    "    print(\"cuda is not available, cpu weights\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    checkpoint = torch.load(os.path.join(DestinationForWeights, os.path.basename(segmentationWeightsURL)), map_location = \"cpu\")\n",
    "    state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9f2a71c-7d16-4025-8e9c-08120c37428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTERNAL_TEST ['Dynamic-OFF22-021.avi', 'Dynamic-OFF22-022.avi', 'Dynamic-OFF22-023-1.avi', 'Dynamic-OFF22-023-2.avi', 'Dynamic-OFF22-024.avi', 'Dynamic-OFF22-025.avi', 'Dynamic-OFF22-026.avi', 'Dynamic-OFF22-027.avi', 'Dynamic-OFF22-028.avi', 'Dynamic-OFF22-029.avi', 'Dynamic-OFF22-030.avi', 'Dynamic-OFF22-031.avi', 'Dynamic-OFF22-032..avi', 'Dynamic-OFF22-033.avi', 'Dynamic-OFF22-034.avi', 'Dynamic-OFF22-035.avi', 'Dynamic-OFF22-036.avi', 'Dynamic-OFF22-037.avi', 'Dynamic-OFF22-038.avi', 'Dynamic-OFF22-039.avi', 'Dynamic-OFF22-040.avi', 'Dynamic-OFF22-041.avi', 'Dynamic-OFF22-042.avi', 'Dynamic-OFF22-043.avi', 'Dynamic-OFF22-045.avi', 'Dynamic-OFF22-046.avi', 'Dynamic-OFF22-047.avi', 'Dynamic-OFF22-048.avi', 'Dynamic-OFF22-049.avi', 'Dynamic-OFF22-050.avi', 'Dynamic-OFF22-051.avi', 'Dynamic-OFF22-052.avi', 'Dynamic-OFF22-053.avi', 'Dynamic-OFF22-055.avi', 'Dynamic-OHT21-003.avi', 'Dynamic-OHT21-005.avi', 'Dynamic-OHT21-006.avi', 'Dynamic-OHT21-007.avi', 'Dynamic-OHT21-011.avi', 'Dynamic-OHT21-012.avi', 'Dynamic-OHT21-013.avi', 'Dynamic-OHT21-014.avi', 'Dynamic-OHT21-015.avi', 'Dynamic-OHT21-016.avi', 'Dynamic-OHT21-017.avi', 'Dynamic-OHT21-019.avi', 'Dynamic-OHT21-021.avi', 'Dynamic-OHT21-022.avi', 'Dynamic-OHT21-024.avi', 'Dynamic-OHT21-025.avi', 'Dynamic-OHT21-031.avi', 'Dynamic-OHT21-032.avi', 'Dynamic-OHT21-033-1.avi', 'Dynamic-OHT21-033-2.avi', 'Dynamic-OHT21-034.avi', 'Dynamic-OHT21-035.avi', 'Dynamic-OHT21-036.avi', 'Dynamic-OHT21-037.avi', 'Dynamic-OHT21-042.avi', 'Dynamic-OHT21-043.avi', 'Dynamic-OHT21-044.avi', 'Dynamic-OHT21-045.avi', 'Dynamic-OHT21-046.avi', 'Dynamic-OHT21-047.avi', 'Dynamic-OHT21-048.avi', 'Dynamic-OHT21-050.avi', 'Dynamic-OHT21-051.avi', 'Dynamic-OHT21-053.avi', 'Dynamic-OHT21-054.avi', 'Dynamic-OHT21-055-1.avi', 'Dynamic-OHT21-055-2.avi', 'Dynamic-OHT21-056.avi', 'Dynamic-OHT21-058.avi', 'Dynamic-OHT21-059.avi', 'Dynamic-OHT21-060.avi', 'Dynamic-OHT21-061.avi', 'Dynamic-OHT21-062.avi', 'Dynamic-OHT21-063.avi', 'Dynamic-OHT21-065.avi', 'Dynamic-OHT21-066.avi', 'Dynamic-OHT21-067.avi', 'Dynamic-OHT21-068-1.avi', 'Dynamic-OHT21-068-2.avi', 'Dynamic-OHT21-070.avi', 'Dynamic-OHT21-071.avi', 'Dynamic-OHT21-074.avi', 'Dynamic-OHT21-075.avi', 'Dynamic-OHT21-076.avi', 'Dynamic-OHT21-077.avi', 'Dynamic-OHT21-079.avi', 'Dynamic-OHT23-001.avi', 'Dynamic-OHT23-002.avi', 'Dynamic-OHT23-003.avi', 'Dynamic-OHT23-004.avi', 'Dynamic-OHT23-006.avi', 'Dynamic-OHT23-009.avi', 'Dynamic-OHT23-010-1.avi']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 13/13 [00:35<00:00,  2.70s/it]\n",
      " 21%|████████▊                                  | 20/97 [07:08<22:21, 17.42s/it]/var/folders/hf/_4l7f46s7sx36_h8zwshkn_41s8kcx/T/ipykernel_34426/3205764825.py:89: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all axes decorations. \n",
      "  plt.tight_layout()\n",
      "100%|███████████████████████████████████████████| 97/97 [32:46<00:00, 20.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Saving videos with segmentations\n",
    "ds = echonet.datasets.Echo(split = \"external_test\", external_test_location = videosFolder,target_type=[\"Filename\"])\n",
    "print(ds.split, ds.fnames)\n",
    "output = destinationFolder\n",
    "save_video = True\n",
    "\n",
    "mean, std = echonet.utils.get_mean_and_std(ds)\n",
    "num_workers = 0\n",
    "batch_size = 64\n",
    "def collate_fn(x):\n",
    "    x, f = zip(*x)\n",
    "    i = list(map(lambda t: t.shape[1], x))\n",
    "    x = torch.as_tensor(np.swapaxes(np.concatenate(x, 1), 0, 1))\n",
    "    return x, f, i\n",
    "\n",
    "dataset = echonet.datasets.Echo(split = \"external_test\", external_test_location = videosFolder,target_type=[\"Filename\"],  # Need filename for saving, and human-selected frames to annotate\n",
    "                                mean=mean, std=std,  # Normalization\n",
    "                                length=None, max_length=None, period=1  # Take all frames\n",
    "                                )\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, num_workers=num_workers, shuffle=False, pin_memory=False, collate_fn=collate_fn)\n",
    "\n",
    "# Save videos with segmentation\n",
    "if save_video and not all(os.path.isfile(os.path.join(output, \"videos\", f)) for f in dataloader.dataset.fnames):\n",
    "    # Only run if missing videos\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    os.makedirs(os.path.join(output, \"videos\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output, \"size\"), exist_ok=True)\n",
    "    echonet.utils.latexify()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with open(os.path.join(output, \"size.csv\"), \"w\") as g:\n",
    "            g.write(\"Filename,Frame,Size,ComputerSmall\\n\")\n",
    "            for (x, (filenames), length) in tqdm.tqdm(dataloader):\n",
    "                # Run segmentation model on blocks of frames one-by-one\n",
    "                # The whole concatenated video may be too long to run together\n",
    "                y = np.concatenate([model(x[i:(i + batch_size), :, :, :].to(device))[\"out\"].detach().cpu().numpy() for i in range(0, x.shape[0], batch_size)])\n",
    "\n",
    "                start = 0\n",
    "                x = x.numpy()\n",
    "\n",
    "                for (i, (filename, offset)) in enumerate(zip(filenames, length)):\n",
    "                    # Extract one video and segmentation predictions\n",
    "                    video = x[start:(start + offset), ...]\n",
    "                    logit = y[start:(start + offset), 0, :, :]\n",
    "\n",
    "                    # Un-normalize video\n",
    "                    video *= std.reshape(1, 3, 1, 1)\n",
    "                    video += mean.reshape(1, 3, 1, 1)\n",
    "\n",
    "                    # Get frames, channels, height, and width\n",
    "                    f, c, h, w = video.shape  # pylint: disable=W0612\n",
    "                    assert c == 3\n",
    "\n",
    "                    # Put two copies of the video side by side\n",
    "                    video = np.concatenate((video, video), 3)\n",
    "\n",
    "                    # If a pixel is in the segmentation, saturate blue channel\n",
    "                    # Leave alone otherwise\n",
    "                    video[:, 0, :, w:] = np.maximum(255. * (logit > 0), video[:, 0, :, w:])  # pylint: disable=E1111\n",
    "\n",
    "                    # Add blank canvas under pair of videos\n",
    "                    video = np.concatenate((video, np.zeros_like(video)), 2)\n",
    "\n",
    "                    # Compute size of segmentation per frame\n",
    "                    size = (logit > 0).sum((1, 2))\n",
    "\n",
    "                    # Identify systole frames with peak detection\n",
    "                    trim_min = sorted(size)[round(len(size) ** 0.05)]\n",
    "                    trim_max = sorted(size)[round(len(size) ** 0.95)]\n",
    "                    trim_range = trim_max - trim_min\n",
    "                    systole = set(scipy.signal.find_peaks(-size, distance=20, prominence=(0.50 * trim_range))[0])\n",
    "\n",
    "                    # Write sizes and frames to file\n",
    "                    for (frame, s) in enumerate(size):\n",
    "                        g.write(\"{},{},{},{}\\n\".format(filename, frame, s,1 if frame in systole else 0))\n",
    "\n",
    "                    # Plot sizes\n",
    "                    fig = plt.figure(figsize=(size.shape[0] / 50 * 1.5, 3))\n",
    "                    plt.scatter(np.arange(size.shape[0]) / 50, size, s=1)\n",
    "                    ylim = plt.ylim()\n",
    "                    for s in systole:\n",
    "                        plt.plot(np.array([s, s]) / 50, ylim, linewidth=1)\n",
    "                    plt.ylim(ylim)\n",
    "                    plt.title(os.path.splitext(filename)[0])\n",
    "                    plt.xlabel(\"Seconds\")\n",
    "                    plt.ylabel(\"Size (pixels)\")\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(output, \"size\", os.path.splitext(filename)[0] + \".pdf\"))\n",
    "                    plt.close(fig)\n",
    "\n",
    "                    # Normalize size to [0, 1]\n",
    "                    size -= size.min()\n",
    "                    size = size / size.max()\n",
    "                    size = 1 - size\n",
    "\n",
    "                    # Iterate the frames in this video\n",
    "                    for (f, s) in enumerate(size):\n",
    "\n",
    "                        # On all frames, mark a pixel for the size of the frame\n",
    "                        try:\n",
    "                            video[:, :, int(round(115 + 100 * s)), int(round(f / len(size) * 200 + 10))] = 255.\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                        if f in systole:\n",
    "                            # If frame is computer-selected systole, mark with a line\n",
    "\n",
    "                            video[:, :, 115:224, int(round(f / len(size) * 200 + 10))] = 255.\n",
    "\n",
    "                        def dash(start, stop, on=10, off=10):\n",
    "                            buf = []\n",
    "                            x = start\n",
    "                            while x < stop:\n",
    "                                buf.extend(range(x, x + on))\n",
    "                                x += on\n",
    "                                x += off\n",
    "                            buf = np.array(buf)\n",
    "                            buf = buf[buf < stop]\n",
    "                            return buf\n",
    "                        d = dash(115, 224)\n",
    "\n",
    "                        try:\n",
    "                            # Get pixels for a circle centered on the pixel\n",
    "                            r, c = skimage.draw.disk((int(round(115 + 100 * s)), int(round(f / len(size) * 200 + 10))), 4.1)\n",
    "\n",
    "                            # On the frame that's being shown, put a circle over the pixel\n",
    "                            video[f, :, r, c] = 255.\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                    # Rearrange dimensions and save\n",
    "                    video = video.transpose(1, 0, 2, 3)\n",
    "                    video = video.astype(np.uint8)\n",
    "                    echonet.utils.savevideo(os.path.join(output, \"videos\", filename), video, 50)\n",
    "\n",
    "                    # Move to next video\n",
    "                    start += offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d608eb2a-bad0-429e-a6b6-b3356569bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from  /Users/vt2113/DonorAI/dynamic/Weights/r2plus1d_18_32_2_pretrained\n",
      "cuda is not available, cpu weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTERNAL_TEST ['Dynamic-OFF22-021.avi', 'Dynamic-OFF22-022.avi', 'Dynamic-OFF22-023-1.avi', 'Dynamic-OFF22-023-2.avi', 'Dynamic-OFF22-024.avi', 'Dynamic-OFF22-025.avi', 'Dynamic-OFF22-026.avi', 'Dynamic-OFF22-027.avi', 'Dynamic-OFF22-028.avi', 'Dynamic-OFF22-029.avi', 'Dynamic-OFF22-030.avi', 'Dynamic-OFF22-031.avi', 'Dynamic-OFF22-032..avi', 'Dynamic-OFF22-033.avi', 'Dynamic-OFF22-034.avi', 'Dynamic-OFF22-035.avi', 'Dynamic-OFF22-036.avi', 'Dynamic-OFF22-037.avi', 'Dynamic-OFF22-038.avi', 'Dynamic-OFF22-039.avi', 'Dynamic-OFF22-040.avi', 'Dynamic-OFF22-041.avi', 'Dynamic-OFF22-042.avi', 'Dynamic-OFF22-043.avi', 'Dynamic-OFF22-045.avi', 'Dynamic-OFF22-046.avi', 'Dynamic-OFF22-047.avi', 'Dynamic-OFF22-048.avi', 'Dynamic-OFF22-049.avi', 'Dynamic-OFF22-050.avi', 'Dynamic-OFF22-051.avi', 'Dynamic-OFF22-052.avi', 'Dynamic-OFF22-053.avi', 'Dynamic-OFF22-055.avi', 'Dynamic-OHT21-003.avi', 'Dynamic-OHT21-005.avi', 'Dynamic-OHT21-006.avi', 'Dynamic-OHT21-007.avi', 'Dynamic-OHT21-011.avi', 'Dynamic-OHT21-012.avi', 'Dynamic-OHT21-013.avi', 'Dynamic-OHT21-014.avi', 'Dynamic-OHT21-015.avi', 'Dynamic-OHT21-016.avi', 'Dynamic-OHT21-017.avi', 'Dynamic-OHT21-019.avi', 'Dynamic-OHT21-021.avi', 'Dynamic-OHT21-022.avi', 'Dynamic-OHT21-024.avi', 'Dynamic-OHT21-025.avi', 'Dynamic-OHT21-031.avi', 'Dynamic-OHT21-032.avi', 'Dynamic-OHT21-033-1.avi', 'Dynamic-OHT21-033-2.avi', 'Dynamic-OHT21-034.avi', 'Dynamic-OHT21-035.avi', 'Dynamic-OHT21-036.avi', 'Dynamic-OHT21-037.avi', 'Dynamic-OHT21-042.avi', 'Dynamic-OHT21-043.avi', 'Dynamic-OHT21-044.avi', 'Dynamic-OHT21-045.avi', 'Dynamic-OHT21-046.avi', 'Dynamic-OHT21-047.avi', 'Dynamic-OHT21-048.avi', 'Dynamic-OHT21-050.avi', 'Dynamic-OHT21-051.avi', 'Dynamic-OHT21-053.avi', 'Dynamic-OHT21-054.avi', 'Dynamic-OHT21-055-1.avi', 'Dynamic-OHT21-055-2.avi', 'Dynamic-OHT21-056.avi', 'Dynamic-OHT21-058.avi', 'Dynamic-OHT21-059.avi', 'Dynamic-OHT21-060.avi', 'Dynamic-OHT21-061.avi', 'Dynamic-OHT21-062.avi', 'Dynamic-OHT21-063.avi', 'Dynamic-OHT21-065.avi', 'Dynamic-OHT21-066.avi', 'Dynamic-OHT21-067.avi', 'Dynamic-OHT21-068-1.avi', 'Dynamic-OHT21-068-2.avi', 'Dynamic-OHT21-070.avi', 'Dynamic-OHT21-071.avi', 'Dynamic-OHT21-074.avi', 'Dynamic-OHT21-075.avi', 'Dynamic-OHT21-076.avi', 'Dynamic-OHT21-077.avi', 'Dynamic-OHT21-079.avi', 'Dynamic-OHT23-001.avi', 'Dynamic-OHT23-002.avi', 'Dynamic-OHT23-003.avi', 'Dynamic-OHT23-004.avi', 'Dynamic-OHT23-006.avi', 'Dynamic-OHT23-009.avi', 'Dynamic-OHT23-010-1.avi']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 13/13 [00:30<00:00,  2.31s/it]\n",
      "/Users/vt2113/opt/anaconda3/envs/echonet/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|█████████████████| 97/97 [06:56<00:00,  4.29s/it, 3297.50 (4060.33) / 0.00]\n"
     ]
    }
   ],
   "source": [
    "# Initialize and Run EF model\n",
    "\n",
    "frames = 32\n",
    "period = 2 #2\n",
    "batch_size = 20\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"loading weights from \", os.path.join(DestinationForWeights, \"r2plus1d_18_32_2_pretrained\"))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is available, original weights\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    checkpoint = torch.load(os.path.join(DestinationForWeights, os.path.basename(ejectionFractionWeightsURL)))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "else:\n",
    "    print(\"cuda is not available, cpu weights\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    checkpoint = torch.load(os.path.join(DestinationForWeights, os.path.basename(ejectionFractionWeightsURL)), map_location = \"cpu\")\n",
    "    state_dict_cpu = {k[7:]: v for (k, v) in checkpoint['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict_cpu)\n",
    "\n",
    "\n",
    "# try some random weights: final_r2+1d_model_regression_EF_sgd_skip1_32frames.pth.tar\n",
    "# scp ouyangd@arthur2:~/Echo-Tracing-Analysis/final_r2+1d_model_regression_EF_sgd_skip1_32frames.pth.tar \"C:\\Users\\Windows\\Dropbox\\Echo Research\\CodeBase\\EchoNetDynamic-Weights\"\n",
    "#Weights = \"final_r2+1d_model_regression_EF_sgd_skip1_32frames.pth.tar\"\n",
    "\n",
    "\n",
    "output = os.path.join(destinationFolder, \"ef_output.csv\")\n",
    "\n",
    "ds = echonet.datasets.Echo(split = \"external_test\", external_test_location = videosFolder)\n",
    "print(ds.split, ds.fnames)\n",
    "\n",
    "mean, std = echonet.utils.get_mean_and_std(ds)\n",
    "\n",
    "kwargs = {\"target_type\": \"EF\",\n",
    "          \"mean\": mean,\n",
    "          \"std\": std,\n",
    "          \"length\": frames,\n",
    "          \"period\": period,\n",
    "          }\n",
    "\n",
    "ds = echonet.datasets.Echo(split = \"external_test\", external_test_location = videosFolder, **kwargs)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(ds, batch_size = 1, num_workers = 5, shuffle = True, pin_memory=(device.type == \"cuda\"))\n",
    "loss, yhat, y = echonet.utils.video.run_epoch(model, test_dataloader,False, None, device, save_all=True)\n",
    "\n",
    "with open(output, \"w\") as g:\n",
    "    for (filename, pred) in zip(ds.fnames, yhat):\n",
    "        for (i,p) in enumerate(pred):\n",
    "            g.write(\"{},{},{:.4f}\\n\".format(filename, i, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ec582da-5798-47cd-b46a-c39265fdb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pixel(inputFolder,destination):\n",
    "    onlyfiles = [f for f in listdir(inputFolder) if (isfile(join(inputFolder, f)) and f[-4:] ==\".dcm\")]\n",
    "    fnames = [f.split('/')[-1] for f in onlyfiles]\n",
    "    x_dim = []\n",
    "    y_dim = []\n",
    "    x = []\n",
    "    y = []\n",
    "    original_shape = []\n",
    "    for f in tqdm.tqdm(onlyfiles):\n",
    "        dataset = dicom.dcmread(os.path.join(inputFolder,f), force=True)\n",
    "        x_dim.append(dataset[(0x18, 0x6011)].value[0][(0x18, 0x6024)].value)\n",
    "        y_dim.append(dataset[(0x18, 0x6011)].value[0][(0x18, 0x6026)].value)\n",
    "        x.append(dataset[(0x18, 0x6011)].value[0][(0x18, 0x602c)].value)\n",
    "        y.append(dataset[(0x18, 0x6011)].value[0][(0x18, 0x602e)].value)\n",
    "        original_shape.append(dataset.pixel_array.shape)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        \"fname\":fnames,\n",
    "        \"x_unit\":x_dim,\n",
    "        \"y_unit\":y_dim,\n",
    "        \"delta_x\":x,\n",
    "        \"delta_y\":y,\n",
    "        \"Original_dim\":original_shape\n",
    "    })\n",
    "    df.to_csv(destination+os.path.sep+'meta_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5abb8013-342b-44cf-be6c-d2e34deb872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 103/103 [04:02<00:00,  2.35s/it]\n"
     ]
    }
   ],
   "source": [
    "## Convert to AVI \n",
    "cropSize = (112,112)\n",
    "onlyfiles = [f for f in listdir(inputFolder) if isfile(join(inputFolder, f))]\n",
    "# for f in onlyfiles:\n",
    "    # makeVideo(os.path.join(inputFolder,f),AVIFolder)    \n",
    "\n",
    "extract_pixel(inputFolder,destinationFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77cd3fe9-6b58-4ac6-87af-a13103494ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(size,file,scale):\n",
    "    x,y = scale[file]\n",
    "    return size*x*y\n",
    "    \n",
    "    \n",
    "    \n",
    "def convert_px_to_cm(input_folder):\n",
    "    resize = (112,112)\n",
    "    # onlyfiles = [f for f in listdir(input_folder) if not isfile(join(input_folder,f))]\n",
    "    df_meta = pd.read_csv(os.path.join(input_folder,'meta_Data.csv'))\n",
    "    df_size = pd.read_csv(os.path.join(input_folder,'size.csv'))\n",
    "    onlyfiles = df_size.Filename.unique()\n",
    "    scale_dict = {}\n",
    "    for f in tqdm.tqdm(onlyfiles):\n",
    "        df_now = df_meta[df_meta.fname==f[:-4]+\".dcm\"]\n",
    "        dims = eval(list(df_now.Original_dim)[0])\n",
    "        x_scale = abs(df_now.delta_x * 0.8*dims[1]/resize[0]).to_numpy()[0]\n",
    "        y_scale = abs(df_now.delta_y * 0.8*dims[1]/resize[1]).to_numpy()[0]\n",
    "        scale_dict[f] = [x_scale,y_scale]\n",
    "        \n",
    "\n",
    "        \n",
    "    df_size['size_cm^2'] = df_size.apply(lambda x: func(x.Size, x.Filename,scale_dict), axis=1)\n",
    "    df_size.to_csv(os.path.join(input_folder,'size_cm.csv'))\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbab7d61-f09c-4a4a-8c91-d6bd82d9e0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 265.90it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_px_to_cm(destinationFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa4416-5614-46f8-afcd-0e58a8298188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
