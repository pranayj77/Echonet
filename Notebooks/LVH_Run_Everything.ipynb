{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bfc4026-8350-45d1-a51b-08b68ee9db6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vt2113/DonorAI/lvh/lvh\n",
      "/Users/vt2113/DonorAI/lvh/lvh\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/vt2113/DonorAI/lvh/lvh\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33997dda-4351-4eff-987a-c3f656e1b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from operator import mod\n",
    "from typing import Union\n",
    "from argparse import ArgumentParser\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import find_peaks\n",
    "import shutil\n",
    "import sys\n",
    "from threading import Thread, Lock\n",
    "\n",
    "from utils import BoolAction, get_clip_dims, read_clip, get_systole_diastole, get_lens_np, get_points_np\n",
    "from utils import get_angles_np, get_pred_measurements, overlay_preds, model_paths\n",
    "from models import PlaxModel as Model\n",
    "from time import time\n",
    "plt_thread_lock = Lock()\n",
    "import re\n",
    "import os, os.path\n",
    "from os.path import splitext,isfile,join\n",
    "from os import listdir\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from pydicom.uid import UID, generate_uid\n",
    "import shutil\n",
    "from multiprocessing import dummy as multiprocessing\n",
    "import subprocess\n",
    "import datetime\n",
    "from datetime import date\n",
    "import sys\n",
    "import cv2\n",
    "#from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from shutil import copy\n",
    "import math\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72012262-8e05-4023-9534-96b4e2f6ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinationFolder = \"/Users/vt2113/Desktop/DICOM #2/LVHOutput\"\n",
    "inputFolder = '/Users/vt2113/Desktop/DICOM #2/LVH Data #2'\n",
    "AVIFolder = '/Users/vt2113/Desktop/DICOM #2/LVHAVI'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c779e4e-f0ac-459f-90dd-33a955231148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(output):\n",
    "\n",
    "    dim1 = output.shape[0]\n",
    "    dim2 = output.shape[1]\n",
    "    \n",
    "    # Mask pixels outside of scanning sector\n",
    "    m1, m2 = np.meshgrid(np.arange(dim2), np.arange(dim1))\n",
    "    \n",
    "\n",
    "    mask = ((m1+m2)>(int(dim2/2) +int(dim2/12))) \n",
    "    # mask = m2> dim1/dim2*(-m1+int(dim2/2)) +int(dim2/10)\n",
    "    mask *=  ((m1-m2)<(int(dim2/2) -int(dim2/12)))\n",
    "    # mask *= -m2< dim1/dim2*(-m1+int(dim2/2)) -int(dim2/10)\n",
    "    \n",
    "    mask = np.reshape(mask, (dim1, dim2)).astype(np.int8)\n",
    "    maskedImage = cv2.bitwise_and(output, output, mask = mask)\n",
    "    \n",
    "    #print(maskedImage.shape)\n",
    "    \n",
    "    return maskedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76c21b5-4595-44a7-81e7-0465ed5863de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVideo(fileToProcess, destinationFolder):\n",
    "\n",
    "    fileName = fileToProcess.split('/')[-1] #\\\\ if windows, / if on mac or sherlock\n",
    "                                             #hex(abs(hash(fileToProcess.split('/')[-1]))).upper()\n",
    "\n",
    "    if not os.path.exists(os.path.join(destinationFolder,fileName[:-4]+'.avi')):\n",
    "        print(os.path.join(destinationFolder,fileName[:-4]+'.avi'))\n",
    "\n",
    "        dataset = dicom.dcmread(fileToProcess, force=True)\n",
    "        testarray = dataset.pixel_array\n",
    "        # print(testarray.shape)\n",
    "        if len(testarray.shape)!=4:\n",
    "            return \n",
    "\n",
    "#         frame0 = testarray[0]\n",
    "#         plt.imshow(frame0[:,:,2])\n",
    "#         mean = np.mean(frame0, axis=1)[:,0]\n",
    "# #         mean = np.mean(mean, axis=1)\n",
    "# #         plt.plot(mean)\n",
    "#         try:\n",
    "#             yCrop = np.where(mean<1)[0][0]\n",
    "#             testarray = testarray[:, yCrop:, :, :]\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "        # bias = int(np.abs(testarray.shape[2] - testarray.shape[1])/2)\n",
    "        # if bias>0:\n",
    "        #     if testarray.shape[1] < testarray.shape[2]:\n",
    "        #         testarray = testarray[:, :, bias:-bias, :]\n",
    "        #     else:\n",
    "        #         testarray = testarray[:, bias:-bias, :, :]\n",
    "\n",
    "\n",
    "        # print(testarray.shape)\n",
    "        frames,height,width,channels = testarray.shape\n",
    "\n",
    "        fps = 30\n",
    "\n",
    "        try:\n",
    "            fps = dataset[(0x18, 0x40)].value\n",
    "        except:\n",
    "            print(\"couldn't find frame rate, default to 30\")\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "        video_filename = os.path.join(destinationFolder, fileName[:-4] + '.avi')\n",
    "        out = cv2.VideoWriter(video_filename, fourcc, fps, cropSize)\n",
    "\n",
    "\n",
    "        for i in range(frames):\n",
    "\n",
    "            outputA = testarray[i,:,:,0]\n",
    "            smallOutput = outputA[int(height/10):(height - int(height/10)), int(height/10):(height - int(height/10))]\n",
    "\n",
    "#             # Resize image\n",
    "            output = cv2.resize(outputA, cropSize, interpolation = cv2.INTER_CUBIC)\n",
    "            finaloutput = mask(output)\n",
    "\n",
    "\n",
    "            finaloutput = cv2.merge([finaloutput,finaloutput,finaloutput])\n",
    "            out.write(finaloutput)\n",
    "\n",
    "        out.release()\n",
    "\n",
    "    else:\n",
    "        print(fileName,\"hasAlreadyBeenProcessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31fbe5d-c46b-409e-a9df-8197b4e7ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pixel(inputFolder,destination):\n",
    "    onlyfiles = [f for f in listdir(inputFolder) if (isfile(join(inputFolder, f)) and f[-4:] ==\".dcm\")]\n",
    "    fnames = [f.split('/')[-1] for f in onlyfiles]\n",
    "    x_dim = []\n",
    "    y_dim = []\n",
    "    x = []\n",
    "    y = []\n",
    "    original_shape = []\n",
    "    for f in tqdm(onlyfiles):\n",
    "        dataset = dicom.dcmread(os.path.join(inputFolder,f), force=True)\n",
    "        try:\n",
    "            x_dim.append(dataset[(0x18, 0x6011)].value[0][(0x18, 0x6024)].value)\n",
    "        except:\n",
    "            x_dim.append(None)\n",
    "        try:\n",
    "            y_dim.append(dataset[(0x18, 0x6011)].value[0][(0x18, 0x6026)].value)\n",
    "        except:\n",
    "            y_dim.append(None)\n",
    "        try:\n",
    "            x.append(dataset[(0x18, 0x6011)].value[0][(0x18, 0x602c)].value)\n",
    "        except:\n",
    "            x.append(None)\n",
    "        try:\n",
    "            y.append(dataset[(0x18, 0x6011)].value[0][(0x18, 0x602e)].value)\n",
    "        except:\n",
    "            y.append(None)\n",
    "        original_shape.append(dataset.pixel_array.shape)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        \"fname\":fnames,\n",
    "        \"x_unit\":x_dim,\n",
    "        \"y_unit\":y_dim,\n",
    "        \"delta_x\":x,\n",
    "        \"delta_y\":y,\n",
    "        \"Original_dim\":original_shape\n",
    "    })\n",
    "    df.to_csv(destination+os.path.sep+'meta_Data.csv')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c601f8-d343-4411-8169-db159ebb8874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LVH-OFF22-035.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-021.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-015.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-014.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-034.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-022.dcm hasAlreadyBeenProcessed\n",
      "/Users/vt2113/Desktop/DICOM #2/LVHAVI/LVH-OFF22-036.avi\n",
      "LVH-OHT21-016.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-017.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-003.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-037.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-023.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-027.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-033.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-007.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-012.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-006.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-032.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-026.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-030.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-024.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-038.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-005.dcm hasAlreadyBeenProcessed\n",
      "/Users/vt2113/Desktop/DICOM #2/LVHAVI/LVH-OHT21-011.avi\n",
      "LVH-OHT21-039.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-025.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-031.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-042.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-076.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-062.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-063.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-077.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT23-006.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-043.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-041.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-055.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT23-004.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT23-010.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-061.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-075.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-048.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-074.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-060.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-054.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-040.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-044.dcm hasAlreadyBeenProcessed\n",
      "/Users/vt2113/Desktop/DICOM #2/LVHAVI/LVH-OFF22-050.avi\n",
      "LVH-OHT23-001.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-058.dcm hasAlreadyBeenProcessed\n",
      "/Users/vt2113/Desktop/DICOM #2/LVHAVI/LVH-OHT21-070.avi\n",
      "LVH-OHT21-071.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-065.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-059.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-051.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-045.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-053.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-047.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT23-002.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-067.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-066.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-072.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT23-003.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-046.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-052.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-043.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-042.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-056.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-048.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-054.dcm hasAlreadyBeenProcessed\n",
      "/Users/vt2113/Desktop/DICOM #2/LVHAVI/LVH-OHT21-068.avi\n",
      "LVH-OHT21-055.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-049.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT23-008.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-079.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-045.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-051.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-050.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-044.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT23-009.dcm hasAlreadyBeenProcessed\n",
      "/Users/vt2113/Desktop/DICOM #2/LVHAVI/LVH-OHT21-052.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LVH-OHT21-046.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-047.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-053.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-028.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-034.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-021.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-035.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-029.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-023.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-036.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-022.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-013-1.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-032.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-033.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-027.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-039.dcm hasAlreadyBeenProcessed\n",
      "/Users/vt2113/Desktop/DICOM #2/LVHAVI/LVH-OHT21-013-2.avi\n",
      "LVH-OHT21-019.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-031.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-025.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-024.dcm hasAlreadyBeenProcessed\n",
      "LVH-OHT21-018.dcm hasAlreadyBeenProcessed\n",
      "LVH-OFF22-038.dcm hasAlreadyBeenProcessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 103/103 [04:16<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "source": [
    "## Convert to AVI \n",
    "cropSize = (640,480)\n",
    "onlyfiles = [f for f in listdir(inputFolder) if isfile(join(inputFolder, f))]\n",
    "for f in onlyfiles:\n",
    "    makeVideo(os.path.join(inputFolder,f),AVIFolder)    \n",
    "\n",
    "extract_pixel(inputFolder,destinationFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56df66ac-38ae-41b8-abc6-101630040afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = model_paths['plax']\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcaf17af-46a2-4a4b-9c43-d63224576fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9027f8af-5776-4884-9a6b-751cad9973c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path,map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bc814bf-f7c1-4e1d-a160-5592328395b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-69.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-55.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-41.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-82.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-020.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-008.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-009.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-40.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-54.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-68.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-56.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-80.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-57.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-43.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-53.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-84.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-27-2.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-01-1.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/.DS_Store'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-85.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-50.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-44.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-78.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-019.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-01-2.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-27-1.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-018.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-79.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-45.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-51.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-36.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-22.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-23.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-35.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-34.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-20.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-08.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-24.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-30.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-18.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-31.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-25.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-33.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-26.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-32.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-17.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-52-2.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-16.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-28.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-14.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-52-1.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-15.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-05.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-39.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-37-1.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-72-1.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-38.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-10.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-04.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-12.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-06.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-72-2.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-37-2.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-07.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-13.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-48.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-74.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-60.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-001.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-015.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-083.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-014.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-75.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-49.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-63.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-77.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-016.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-002.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-003.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-017.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-76.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-013.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-007.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-006.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-012.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-67.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-71.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-004.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-010.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-011.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OFF22-005.avi'), PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-58.avi')]\n"
     ]
    }
   ],
   "source": [
    "paths = Path(AVIFolder)\n",
    "paths = list(paths.iterdir())\n",
    "print(paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91cb3bae-16a0-4dfb-abd1-94d2fa97c904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-85.avi')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b29a319-3add-4852-83b1-b1236769a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, w_all, h_all), fnames = get_clip_dims(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b6695c9-3903-4d68-ac93-f7b9f0978469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/_4l7f46s7sx36_h8zwshkn_41s8kcx/T/ipykernel_83255/1172152414.py:3: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  'path': np.concatenate([np.array([str(p)] * ni, dtype=np.object) for ni, p in zip(n, paths)]),\n"
     ]
    }
   ],
   "source": [
    "frame_map = pd.DataFrame({\n",
    "            'frame': np.concatenate([np.arange(ni) for ni in n]),\n",
    "            'path': np.concatenate([np.array([str(p)] * ni, dtype=np.object) for ni, p in zip(n, paths)]),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c85ddcfb-72f8-4f9d-8009-936515da3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "h=480\n",
    "w=640\n",
    "channels_in=3\n",
    "channels_out=4\n",
    "verbose=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2ffe2c7-0394-4c1b-9b08-94842f8c9503",
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = dict()  # clips currently being processed\n",
    "batch = np.zeros((batch_size, h, w, channels_in))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce76fcf6-af5d-442e-8ee2-968f4fef5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_np(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Run inference on a numpy array video.\n",
    "    Args:\n",
    "        x (np.ndarray): shape=(n, h, w, 3)\n",
    "    Returns:\n",
    "        (np.ndarray): shape=(n, h, w, 4). Raw model predictions.\n",
    "    \"\"\"\n",
    "    input_tensor = torch.tensor(x,dtype = torch.float32,device = device, requires_grad = False).permute(0,3,1,2)/255\n",
    "    with torch.no_grad():\n",
    "        preds_tensor = model(input_tensor)\n",
    "        preds_tensor = preds_tensor.permute(0,2,3,1)\n",
    "    input_tensor = input_tensor.detach().numpy()\n",
    "    preds = preds_tensor.detach().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58d571-b0c8-46c3-8ee5-2ed83a6719c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/628 [00:00<?, ?it/s]/var/folders/hf/_4l7f46s7sx36_h8zwshkn_41s8kcx/T/ipykernel_83255/2351262209.py:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  clips[p] = (c, np.zeros((len(c), h, w, channels_out), dtype=np.float))\n",
      " 90%|██████████████████████████████████▎   | 568/628 [10:21:54<58:52, 58.87s/it]"
     ]
    }
   ],
   "source": [
    "for si in tqdm(range(0, len(frame_map), batch_size)) if verbose else range(0, len(frame_map), batch_size):\n",
    "        start = time() \n",
    "        # Get batch files\n",
    "        batch_map = frame_map.iloc[si:min(si + batch_size, len(frame_map))]\n",
    "        batch_paths = batch_map['path'].unique()\n",
    "        l = list(clips.items())\n",
    "        # print(\"Get batch files\")\n",
    "        # print(time()-start)\n",
    "        start = time() \n",
    "        # Check if inference has finished for all current clips\n",
    "        # and yield results for any finished.\n",
    "#         for k, v in l:\n",
    "#             if k not in batch_paths:\n",
    "#                 clips.pop(k)\n",
    "        # print(\"Check inference\")\n",
    "        # print(time()-start)\n",
    "        # start = time() \n",
    "\n",
    "        # Generate batch\n",
    "        for p in batch_paths:\n",
    "            # print('Reading again')\n",
    "            if p not in clips:\n",
    "                # print('Reading again 2')\n",
    "                c = read_clip(p, res=(w, h))\n",
    "                clips[p] = (c, np.zeros((len(c), h, w, channels_out), dtype=np.float))\n",
    "            batch[:len(batch_map)][batch_map['path'] == p] = clips[p][0][batch_map[batch_map['path'] == p]['frame']]\n",
    "        \n",
    "        # print(\"Geenerate Batch\")\n",
    "        # print(time()-start)\n",
    "        start = time() \n",
    "\n",
    "        # Run inference and set results\n",
    "        preds = run_model_np(batch[:len(batch_map)])\n",
    "        # print(\"Run model\")\n",
    "        # print(time()-start)\n",
    "        start = time()\n",
    "        \n",
    "        for p in batch_paths:\n",
    "            clips[p][1][batch_map[batch_map['path'] == p]['frame']] = preds[batch_map['path'] == p]\n",
    "        \n",
    "        # print(\"Run Inference\")\n",
    "        # print(time()-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d19db5fc-ff1b-4fa6-b95c-41581efa766a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 480, 640, 4)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clips['/Users/vt2113/Desktop/OHT DICOMS/LVHAVI/LVH-OHT22-69.avi'][1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d98221-356f-4586-ab0f-2cf33208fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(\n",
    "            p: Union[str, Path], fn: str, clip: np.ndarray, preds: np.ndarray, \n",
    "            csv=True, avi=True, plot=True, npy=False, angle_threshold=30\n",
    "        ) -> None:\n",
    "    \"\"\"Save results for model predictions. All results are saved to a new directory within the \n",
    "    output path with the name [fn]. Frame-by-frame analysis to predict ES and ED is used and \n",
    "    results are saved to [fn].csv.\n",
    "\n",
    "    Args:\n",
    "        p (Union[str, Path]): output path to save to\n",
    "        fn (str): output filename\n",
    "        clip (np.ndarray): shape=(n, h, w, 3), input clip used to run inference\n",
    "        preds (np.ndarray): shape=(n, h, w, 4), model predictions from input clip\n",
    "        csv (bool, optional): Save frame-by-frame results to .csv. Defaults to True.\n",
    "        avi (bool, optional): Save prediction animation as .avi. Defaults to True.\n",
    "        plot (bool, optional): Save measurement vs time plot as .png. Defaults to True.\n",
    "        npy (bool, optional): Save raw predictions as numpy .npy. Defaults to False.\n",
    "        angle_threshold (int, optional): Angle between measurement lines above which are \n",
    "            considered 'bad'. Defaults to 30.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create folder\n",
    "    folder_name = fn.replace('.avi', '').replace('.', '_')\n",
    "    inf_path = p / folder_name\n",
    "    if not inf_path.exists():\n",
    "        inf_path.mkdir()\n",
    "    \n",
    "    # Save raw predictions as .npy\n",
    "    if npy:\n",
    "        print(f'Saving npy {inf_path / (folder_name)}')\n",
    "        np.save(inf_path / (folder_name + '.npy'), preds)\n",
    "    pred_pts, pred_lens, sys_i, dia_i, angles = get_pred_measurements(preds)\n",
    "\n",
    "    # Save predicted points to .csv\n",
    "    if csv:\n",
    "        phase = np.array([''] * len(pred_pts), dtype=object)\n",
    "        phase[sys_i] = 'ES'\n",
    "        phase[dia_i] = 'ED'\n",
    "        df = pd.DataFrame({\n",
    "            'frame': np.arange(len(pred_pts)),\n",
    "            'X1': pred_pts[:, 0, 0],\n",
    "            'Y1': pred_pts[:, 0, 1],\n",
    "            'X2': pred_pts[:, 1, 0],\n",
    "            'Y2': pred_pts[:, 1, 1],\n",
    "            'X3': pred_pts[:, 2, 0],\n",
    "            'Y3': pred_pts[:, 2, 1],\n",
    "            'X4': pred_pts[:, 3, 0],\n",
    "            'Y4': pred_pts[:, 3, 1],\n",
    "            'LVPW': pred_lens[:, 0],\n",
    "            'LVID': pred_lens[:, 1],\n",
    "            'IVS': pred_lens[:, 2],\n",
    "            'predicted_phase': phase,\n",
    "            'LVPW_LVID_angle': angles[:, 0],\n",
    "            'LVID_IVS_angle': angles[:, 1],\n",
    "            'bad_angle': (abs(angles[:, 0]) > angle_threshold) | (abs(angles[:, 1]) > angle_threshold)\n",
    "        })\n",
    "        df.set_index('frame')\n",
    "        df.to_csv(inf_path / (folder_name + '.csv'))\n",
    "\n",
    "    # Save an animation of the predictions overlayed on the cropped video as .avi\n",
    "    if avi:\n",
    "        with plt_thread_lock:\n",
    "            # make_animation(inf_path / (folder_name + '.avi'), clip, preds, pred_pts, pred_lens, sys_i, dia_i)\n",
    "            make_animation_cv2(inf_path / (folder_name + '.avi'), clip, preds, pred_pts)\n",
    "    \n",
    "    # Save a plot of measurements vs time for whole clip\n",
    "    if plot:\n",
    "        make_plot(inf_path / (folder_name + '.png'), folder_name, pred_lens, sys_i, dia_i)\n",
    "\n",
    "def make_animation(\n",
    "            save_path: Union[Path, str], clip: np.ndarray, preds: np.ndarray, \n",
    "            pred_pts: np.ndarray, pred_lens: np.ndarray, sys_i, dia_i, \n",
    "            figsize=(12, 12), units='PX', fps=50\n",
    "        ) -> None:\n",
    "    \n",
    "    \"\"\"Save animation of predictions using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        save_path (Union[Path, str]): Location to save animation .avi to\n",
    "        clip (np.ndarray): shape=(n, h, w, 3). Input video used for inference.\n",
    "        preds (np.ndarray): shape=(n, h, w, 4). Raw model predictions.\n",
    "        pred_pts (np.ndarray): shape=(n, 4, 2). Predicted points for measurements.\n",
    "        pred_lens (np.ndarray): shape=(n, 3). Predicted measurement values [LVPW, LVID, IVS]\n",
    "        sys_i (array-like): indices predicted to be end systole\n",
    "        dia_i (array-like): indices predicted to be end diastole\n",
    "        figsize (tuple, optional): plt figure size. Defaults to (12, 12).\n",
    "        units (str, optional): Units to show on plot. Defaults to 'PX'.\n",
    "        fps (int, optional): Frame rate so save animation in. Defaults to 50.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure Path object\n",
    "    if isinstance(save_path, str):\n",
    "        save_path = Path(save_path)\n",
    "    \n",
    "    # Setup figure layout and static plot\n",
    "    grid = plt.GridSpec(4, 1)\n",
    "    fig = plt.figure(0, figsize=figsize)\n",
    "    ax1 = fig.add_subplot(grid[3:, 0])\n",
    "    ax2 = fig.add_subplot(grid[:3, 0])\n",
    "    for l, n in zip(pred_lens.T, ['LVPW', 'LVID', 'IVS']):\n",
    "        ax1.plot(l, label=n)\n",
    "    l1, = ax1.plot([0, 0, 0], pred_lens[0], 'ro')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel('Frame')\n",
    "    ax1.set_ylabel(f'Measurement [{units}]')\n",
    "    ax1.vlines(sys_i, pred_lens.min(), pred_lens.max(), linestyles='dashed', colors='b', label='Systole')\n",
    "    ax1.vlines(dia_i, pred_lens.min(), pred_lens.max(), linestyles='dashed', colors='g', label='Diastole')\n",
    "    im = ax2.imshow(overlay_preds(preds[0], clip[0] / 255))\n",
    "    l2, = ax2.plot(*pred_pts[0].T, 'C1o-')\n",
    "    ax2.set_title(save_path.name)\n",
    "\n",
    "    # Modifies plot for each frame of animation\n",
    "    def animate(i):\n",
    "        im.set_data(overlay_preds(preds[i], clip[i] / 255))\n",
    "        l1.set_data([i, i , i], pred_lens[i])\n",
    "        l2.set_data(*pred_pts[i].T)\n",
    "\n",
    "    # Save animation\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(clip), interval=1000 / fps)\n",
    "    writer = animation.FFMpegWriter(fps)\n",
    "    ani.save(save_path, writer)\n",
    "\n",
    "    del fig\n",
    "\n",
    "def make_plot(\n",
    "            save_path: Union[Path, str], title: str, pred_lens: np.ndarray, \n",
    "            sys_i, dia_i, figsize=(8, 6)\n",
    "        ) -> None:\n",
    "    \"\"\"Save a plot showing measurement values over time.\n",
    "\n",
    "    Args:\n",
    "        save_path (Union[Path, str]): .png path to save plot to.\n",
    "        title (str): Plot title.\n",
    "        pred_lens (np.ndarray): shape=(n, 3). Predicted measurements [LVPW, LVID, IVS]\n",
    "        sys_i (array-like): indices predicted to be end systole\n",
    "        dia_i (array-like): indices predicted to be end diastole\n",
    "        figsize (tuple, optional): plt figure size. Defaults to (8, 6).\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(1, figsize=figsize)\n",
    "    plt.clf()\n",
    "    for l, n in zip(pred_lens.T, ['LVPW', 'LVID', 'IVS']):\n",
    "        plt.plot(l, label=n)\n",
    "    plt.plot(sys_i, pred_lens[sys_i], 'r+')\n",
    "    plt.plot(dia_i, pred_lens[dia_i], 'rx')\n",
    "    plt.plot([], [], 'rx', label='Diastole')\n",
    "    plt.plot([], [], 'r+', label='Systole')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Measurement [px]')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "\n",
    "def make_animation_cv2(\n",
    "            save_path: Union[Path, str], clip: np.ndarray, preds: np.ndarray, pred_pts: np.ndarray, \n",
    "            fps=30.0, line_color=(1, 1, 0), point_color=(1, 0.5, 0), linewidth=2, markersize=4\n",
    "        ) -> None:\n",
    "    \"\"\"Creates an animation with predictions overlayed on top of the clip.\n",
    "\n",
    "    Args:\n",
    "        save_path (Union[Path, str]): .avi path to save animation to.\n",
    "        clip (np.ndarray): shape=(n, h, w, 3). Input video used for inference.\n",
    "        preds (np.ndarray): shape=(n, h, w, 4). Raw model predictions.\n",
    "        pred_pts (np.ndarray): shape=(n, 4, 2). Predicted points for measurements.\n",
    "        fps (float, optional): Animation frame rate. Defaults to 30.0.\n",
    "        line_color (tuple, optional): Color of measurement lines. Defaults to (1, 1, 0).\n",
    "        point_color (tuple, optional): Color of measurement endpoints. Defaults to (1, 0.5, 0).\n",
    "        linewidth (int, optional): Width of measurement lines. Defaults to 2.\n",
    "        markersize (int, optional): Size of measurement endpoints. Defaults to 4.\n",
    "    \"\"\"\n",
    "    out = cv2.VideoWriter(str(save_path), cv2.VideoWriter_fourcc(*'MJPG'), fps, (clip.shape[2], clip.shape[1]))\n",
    "    for frame, pred, line in zip(clip, preds, pred_pts):\n",
    "        \n",
    "        # Overlay raw predictions\n",
    "        img = overlay_preds(pred, frame / 255)\n",
    "        if not np.isnan(line).any():\n",
    "            line = line.round().astype(int)\n",
    "        \n",
    "            # Draw measurement\n",
    "            for pt0, pt1 in zip(line[:-1], line[1:]):\n",
    "                img = cv2.line(img, tuple(pt0), tuple(pt1), line_color, linewidth)\n",
    "            for pt in line:\n",
    "                img = cv2.circle(img, tuple(pt), radius=markersize, color=point_color, thickness=-1)\n",
    "        \n",
    "        # Write to file\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        out.write(img[:, :, ::-1])\n",
    "    \n",
    "    # Close file\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6869d71-c61e-4ee3-81a3-9365fe42d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn,(raw,preds) in clips.items():\n",
    "    fn = fn.split('/')[-1]\n",
    "    save_preds(Path(destinationFolder),fn,raw,preds,csv=True, avi=True, plot=True,npy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da283d91-84ff-44c6-b939-fa26885b6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'1':(0,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a1d191e-4bb9-46e8-af66-1b0aff85b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_px_to_cm(input_folder):\n",
    "    resize = (480,640)\n",
    "    onlyfiles = [f for f in listdir(input_folder) if not isfile(join(input_folder,f))]\n",
    "    onlyfiles.pop(24)\n",
    "    df_meta = pd.read_csv(os.path.join(input_folder,'meta_Data.csv'))\n",
    "    i = 0\n",
    "    for f in tqdm(onlyfiles):\n",
    "        df = pd.read_csv(os.path.join('/Users/vt2113/Desktop/DICOM #2/LVHOutput_mod',f,f+'.csv'))\n",
    "        df_now = df_meta[df_meta.fname==f+\".dcm\"]\n",
    "        dims = eval(list(df_now.Original_dim)[0])\n",
    "        x_scale = abs(df_now.delta_x * dims[1]/resize[0]).to_numpy()[0]\n",
    "        y_scale = abs(df_now.delta_y * dims[2]/resize[1]).to_numpy()[0]\n",
    "        pts = np.array([[df.X1.to_numpy() *x_scale,df.Y1.to_numpy() *y_scale],\n",
    "                        [df.X2.to_numpy() *x_scale,df.Y2.to_numpy() *y_scale],\n",
    "                        [df.X3.to_numpy() *x_scale,df.Y3.to_numpy() *y_scale],\n",
    "                        [df.X4.to_numpy() *x_scale,df.Y4.to_numpy() *y_scale]])\n",
    "        \n",
    "        df['X1_cm'] = df.X1 * x_scale\n",
    "        df['X2_cm'] = df.X2 * x_scale\n",
    "        df['X3_cm'] = df.X3 * x_scale\n",
    "        df['X4_cm'] = df.X4 * x_scale\n",
    "        df['Y1_cm'] = df.Y1 * y_scale\n",
    "        df['Y2_cm'] = df.Y2 * y_scale\n",
    "        df['Y3_cm'] = df.Y3 * y_scale\n",
    "        df['Y4_cm'] = df.Y4 * y_scale\n",
    "        pts = np.moveaxis(pts,-1,0)\n",
    "        pred_lens = get_lens_np(pts)\n",
    "        df['LVPW_cm'] =  np.squeeze(pred_lens[:, 0])\n",
    "        df['LVID_cm'] = np.squeeze(pred_lens[:, 1])\n",
    "    \n",
    "        df['IVS_cm'] =  np.squeeze(pred_lens[:, 2])\n",
    "        df.to_csv(os.path.join(input_folder,f,f+'_cm.csv'))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ca44779-9136-40e6-b089-3fea5d8a6d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 54/54 [00:01<00:00, 34.87it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_px_to_cm(destinationFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88321827-774a-47a4-857d-93b63528ead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 30/30 [02:47<00:00,  5.59s/it]\n"
     ]
    }
   ],
   "source": [
    "onlyfiles = [f for f in listdir(destinationFolder) if not isfile(join(destinationFolder,f))]\n",
    "for f in tqdm(onlyfiles[25:]):\n",
    "    preds = np.load(os.path.join(destinationFolder,f,f+'.npy'))\n",
    "    clip = read_clip(os.path.join(AVIFolder,f+'.avi'))\n",
    "    try:\n",
    "        save_preds(Path('/Users/vt2113/Desktop/DICOM #2/LVHOutput_mod'),f,clip,preds,csv=True,avi=False,plot=False,npy=False)\n",
    "    except:\n",
    "        print(f\"Skipped {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4920cf1-9410-4bd4-a0ea-9d6093b8100e",
   "metadata": {},
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74ba820b-4ae9-4907-81dc-0019a05da5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LVH-OHT21-072', 'LVH-OHT21-067', 'LVH-OFF22-053', 'LVH-OFF22-047', 'LVH-OHT23-002', 'LVH-OHT21-042', 'LVH-OHT21-056', 'LVH-OHT21-043', 'LVH-OFF22-049', 'LVH-OHT21-055', 'LVH-OHT21-054', 'LVH-OFF22-048', 'LVH-OHT23-009', 'LVH-OHT21-050', 'LVH-OHT21-044', 'LVH-OHT21-079', 'LVH-OHT21-045', 'LVH-OHT21-051', 'LVH-OHT23-008', 'LVH-OHT21-047', 'LVH-OHT21-053', 'LVH-OHT21-046', 'LVH-OFF22-029', 'LVH-OHT21-021', 'LVH-OHT21-035', 'LVH-OHT21-034', 'LVH-OFF22-028', 'LVH-OHT21-036', 'LVH-OHT21-022', 'LVH-OHT21-023', 'LVH-OHT21-033', 'LVH-OHT21-027', 'LVH-OHT21-032', 'LVH-OHT21-013-1', 'LVH-OFF22-038', 'LVH-OHT21-024', 'LVH-OHT21-018', 'LVH-OHT21-019', 'LVH-OHT21-031', 'LVH-OHT21-025', 'LVH-OFF22-039']\n"
     ]
    }
   ],
   "source": [
    "onlyfilesAVI = [f[:-4] for f in listdir(AVIFolder) if isfile(join(AVIFolder,f))]\n",
    "onlyfilesOut = [f for f in listdir(destinationFolder) if not isfile(join(destinationFolder,f))]\n",
    "s = set(onlyfilesOut)\n",
    "left_files = [f for f in onlyfilesAVI if f not in s]\n",
    "print(left_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2368d5d-4ea1-4142-887f-1aea8a05bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "trg = '/Users/vt2113/Desktop/DICOM #2/AVISubset'\n",
    "for fname in left_files:\n",
    "    # copying the files to the\n",
    "    # destination directory\n",
    "    shutil.copy2(os.path.join(AVIFolder,fname+'.avi'), trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c06d4e-949d-446d-bb8f-d7219f329e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
