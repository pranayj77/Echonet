{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b08609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from operator import mod\n",
    "from typing import Union\n",
    "from argparse import ArgumentParser\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import find_peaks\n",
    "import shutil\n",
    "import sys\n",
    "from threading import Thread, Lock\n",
    "\n",
    "from utils import BoolAction, get_clip_dims, read_clip, get_systole_diastole, get_lens_np, get_points_np\n",
    "from utils import get_angles_np, get_pred_measurements, overlay_preds, model_paths\n",
    "from models import PlaxModel as Model\n",
    "from time import time\n",
    "plt_thread_lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33577dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ffb1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01cd177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = model_paths['plax']\n",
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ee8ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c49b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9776cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10baac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model,depth = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6230d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "def54a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path,map_location=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2a4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = Path('/athena/sablab/scratch/prj4005/lvhSubset')\n",
    "paths = list(paths.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7631c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, w_all, h_all), fnames = get_clip_dims(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8f919cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_254149/1172152414.py:3: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  'path': np.concatenate([np.array([str(p)] * ni, dtype=np.object) for ni, p in zip(n, paths)]),\n"
     ]
    }
   ],
   "source": [
    "frame_map = pd.DataFrame({\n",
    "            'frame': np.concatenate([np.arange(ni) for ni in n]),\n",
    "            'path': np.concatenate([np.array([str(p)] * ni, dtype=np.object) for ni, p in zip(n, paths)]),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c762d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "h=480\n",
    "w=640\n",
    "channels_in=3\n",
    "channels_out=4\n",
    "verbose=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd216e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = dict()  # clips currently being processed\n",
    "batch = np.zeros((batch_size, h, w, channels_in))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bccee524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_np(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Run inference on a numpy array video.\n",
    "    Args:\n",
    "        x (np.ndarray): shape=(n, h, w, 3)\n",
    "    Returns:\n",
    "        (np.ndarray): shape=(n, h, w, 4). Raw model predictions.\n",
    "    \"\"\"\n",
    "    input_tensor = torch.tensor(x,dtype = torch.float16,device = device, requires_grad = False).permute(0,3,1,2)/255\n",
    "    with torch.no_grad():\n",
    "        preds_tensor = model.half()(input_tensor)\n",
    "        preds_tensor.permute(0,2,3,1)\n",
    "    input_tensor = input_tensor.detach().cpu().numpy()\n",
    "    preds = preds_tensor.detach().cpu().numpy()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e3a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0306fecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get batch files\n",
      "0.00033211708068847656\n",
      "Check inference\n",
      "2.86102294921875e-06\n",
      "Reading again\n",
      "Geenerate Batch\n",
      "0.012169361114501953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:44<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m start \u001b[39m=\u001b[39m time() \n\u001b[1;32m     32\u001b[0m \u001b[39m# Run inference and set results\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m preds \u001b[39m=\u001b[39m run_model_np(batch[:\u001b[39mlen\u001b[39;49m(batch_map)])\n\u001b[1;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRun model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(time()\u001b[39m-\u001b[39mstart)\n",
      "Cell \u001b[0;32mIn[45], line 12\u001b[0m, in \u001b[0;36mrun_model_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     preds_tensor \u001b[39m=\u001b[39m model(input_tensor)\n\u001b[1;32m     11\u001b[0m     preds_tensor\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m input_tensor \u001b[39m=\u001b[39m input_tensor\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     13\u001b[0m preds \u001b[39m=\u001b[39m preds_tensor\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m preds\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for si in tqdm(range(0, len(frame_map), batch_size)) if verbose else range(0, len(frame_map), batch_size):\n",
    "        start = time() \n",
    "        # Get batch files\n",
    "        batch_map = frame_map.iloc[si:min(si + batch_size, len(frame_map))]\n",
    "        batch_paths = batch_map['path'].unique()\n",
    "        l = list(clips.items())\n",
    "        print(\"Get batch files\")\n",
    "        print(time()-start)\n",
    "        start = time() \n",
    "        # Check if inference has finished for all current clips\n",
    "        # and yield results for any finished.\n",
    "#         for k, v in l:\n",
    "#             if k not in batch_paths:\n",
    "#                 clips.pop(k)\n",
    "        print(\"Check inference\")\n",
    "        print(time()-start)\n",
    "        start = time() \n",
    "\n",
    "        # Generate batch\n",
    "        for p in batch_paths:\n",
    "            print('Reading again')\n",
    "            if p not in clips:\n",
    "                print('Reading again 2')\n",
    "                c = read_clip(p, res=(w, h))\n",
    "                clips[p] = (c, np.zeros((len(c), h, w, channels_out), dtype=np.float))\n",
    "            batch[:len(batch_map)][batch_map['path'] == p] = clips[p][0][batch_map[batch_map['path'] == p]['frame']]\n",
    "        \n",
    "        print(\"Geenerate Batch\")\n",
    "        print(time()-start)\n",
    "        start = time() \n",
    "\n",
    "        # Run inference and set results\n",
    "        preds = run_model_np(batch[:len(batch_map)])\n",
    "        print(\"Run model\")\n",
    "        print(time()-start)\n",
    "        start = time()\n",
    "        \n",
    "        for p in batch_paths:\n",
    "            clips[p][1][batch_map[batch_map['path'] == p]['frame']] = preds[batch_map['path'] == p]\n",
    "        \n",
    "        print(\"Run Inference\")\n",
    "        print(time()-start)\n",
    "        \n",
    "        \n",
    "        !nvidia-smi \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c92cadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = read_clip(batch_paths[0], res=(w, h))\n",
    "preds = np.zeros((227,h,w,4))\n",
    "\n",
    "# for i in tqdm(range(0,227,4)):\n",
    "#     start = time()\n",
    "#     input_tensor = c[i:i+4,:,:,:]\n",
    "#     print(input_tensor.shape)\n",
    "#     preds[i:i+4,:,:,:] = run_model_np(input_tensor)\n",
    "#     print(time()-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eaccbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc1e1877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 10 19:17:57 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  A40                 On   | 00000000:65:00.0 Off |                    0 |\n",
      "|  0%   35C    P0   293W / 300W |   3408MiB / 45634MiB |     65%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     54866      C   ...a/envs/echo/bin/python3.9     3405MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   78211 KB |     849 MB |  297999 MB |  297922 MB |\n",
      "|       from large pool |   64512 KB |     836 MB |  297931 MB |  297868 MB |\n",
      "|       from small pool |   13699 KB |      34 MB |      68 MB |      54 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   78211 KB |     849 MB |  297999 MB |  297922 MB |\n",
      "|       from large pool |   64512 KB |     836 MB |  297931 MB |  297868 MB |\n",
      "|       from small pool |   13699 KB |      34 MB |      68 MB |      54 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  116736 KB |    1696 MB |    1696 MB |    1582 MB |\n",
      "|       from large pool |  100352 KB |    1660 MB |    1660 MB |    1562 MB |\n",
      "|       from small pool |   16384 KB |      36 MB |      36 MB |      20 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   38525 KB |  258237 KB |  224507 MB |  224469 MB |\n",
      "|       from large pool |   35840 KB |  255552 KB |  224437 MB |  224402 MB |\n",
      "|       from small pool |    2685 KB |    8490 KB |      70 MB |      67 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     362    |     724    |   12394    |   12032    |\n",
      "|       from large pool |      19    |      48    |   10913    |   10894    |\n",
      "|       from small pool |     343    |     676    |    1481    |    1138    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     362    |     724    |   12394    |   12032    |\n",
      "|       from large pool |      19    |      48    |   10913    |   10894    |\n",
      "|       from small pool |     343    |     676    |    1481    |    1138    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      13    |      42    |      42    |      29    |\n",
      "|       from large pool |       5    |      24    |      24    |      19    |\n",
      "|       from small pool |       8    |      18    |      18    |      10    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      30    |      35    |    7399    |    7369    |\n",
      "|       from large pool |       5    |      10    |    7233    |    7228    |\n",
      "|       from small pool |      25    |      25    |     166    |     141    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58de97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(\n",
    "            p: Union[str, Path], fn: str, clip: np.ndarray, preds: np.ndarray, \n",
    "            csv=True, avi=True, plot=True, npy=False, angle_threshold=30\n",
    "        ) -> None:\n",
    "    \"\"\"Save results for model predictions. All results are saved to a new directory within the \n",
    "    output path with the name [fn]. Frame-by-frame analysis to predict ES and ED is used and \n",
    "    results are saved to [fn].csv.\n",
    "\n",
    "    Args:\n",
    "        p (Union[str, Path]): output path to save to\n",
    "        fn (str): output filename\n",
    "        clip (np.ndarray): shape=(n, h, w, 3), input clip used to run inference\n",
    "        preds (np.ndarray): shape=(n, h, w, 4), model predictions from input clip\n",
    "        csv (bool, optional): Save frame-by-frame results to .csv. Defaults to True.\n",
    "        avi (bool, optional): Save prediction animation as .avi. Defaults to True.\n",
    "        plot (bool, optional): Save measurement vs time plot as .png. Defaults to True.\n",
    "        npy (bool, optional): Save raw predictions as numpy .npy. Defaults to False.\n",
    "        angle_threshold (int, optional): Angle between measurement lines above which are \n",
    "            considered 'bad'. Defaults to 30.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create folder\n",
    "    folder_name = fn.replace('.avi', '').replace('.', '_')\n",
    "    inf_path = p / folder_name\n",
    "    if not inf_path.exists():\n",
    "        inf_path.mkdir()\n",
    "    \n",
    "    # Save raw predictions as .npy\n",
    "    if npy:\n",
    "        print(f'Saving npy {inf_path / (folder_name)}')\n",
    "        np.save(inf_path / (folder_name + '.npy'), preds)\n",
    "    pred_pts, pred_lens, sys_i, dia_i, angles = get_pred_measurements(preds)\n",
    "\n",
    "    # Save predicted points to .csv\n",
    "    if csv:\n",
    "        phase = np.array([''] * len(pred_pts), dtype=object)\n",
    "        phase[sys_i] = 'ES'\n",
    "        phase[dia_i] = 'ED'\n",
    "        df = pd.DataFrame({\n",
    "            'frame': np.arange(len(pred_pts)),\n",
    "            'X1': pred_pts[:, 0, 0],\n",
    "            'Y1': pred_pts[:, 0, 0],\n",
    "            'X2': pred_pts[:, 1, 0],\n",
    "            'Y2': pred_pts[:, 1, 0],\n",
    "            'X2': pred_pts[:, 2, 0],\n",
    "            'Y3': pred_pts[:, 2, 0],\n",
    "            'X4': pred_pts[:, 3, 0],\n",
    "            'Y4': pred_pts[:, 3, 0],\n",
    "            'LVPW': pred_lens[:, 0],\n",
    "            'LVID': pred_lens[:, 1],\n",
    "            'IVS': pred_lens[:, 2],\n",
    "            'predicted_phase': phase,\n",
    "            'LVPW_LVID_angle': angles[:, 0],\n",
    "            'LVID_IVS_angle': angles[:, 1],\n",
    "            'bad_angle': (abs(angles[:, 0]) > angle_threshold) | (abs(angles[:, 1]) > angle_threshold)\n",
    "        })\n",
    "        df.set_index('frame')\n",
    "        df.to_csv(inf_path / (folder_name + '.csv'))\n",
    "\n",
    "    # Save an animation of the predictions overlayed on the cropped video as .avi\n",
    "    if avi:\n",
    "        with plt_thread_lock:\n",
    "            # make_animation(inf_path / (folder_name + '.avi'), clip, preds, pred_pts, pred_lens, sys_i, dia_i)\n",
    "            make_animation_cv2(inf_path / (folder_name + '.avi'), clip, preds, pred_pts)\n",
    "    \n",
    "    # Save a plot of measurements vs time for whole clip\n",
    "    if plot:\n",
    "        make_plot(inf_path / (folder_name + '.png'), folder_name, pred_lens, sys_i, dia_i)\n",
    "\n",
    "def make_animation(\n",
    "            save_path: Union[Path, str], clip: np.ndarray, preds: np.ndarray, \n",
    "            pred_pts: np.ndarray, pred_lens: np.ndarray, sys_i, dia_i, \n",
    "            figsize=(12, 12), units='PX', fps=50\n",
    "        ) -> None:\n",
    "    \n",
    "    \"\"\"Save animation of predictions using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        save_path (Union[Path, str]): Location to save animation .avi to\n",
    "        clip (np.ndarray): shape=(n, h, w, 3). Input video used for inference.\n",
    "        preds (np.ndarray): shape=(n, h, w, 4). Raw model predictions.\n",
    "        pred_pts (np.ndarray): shape=(n, 4, 2). Predicted points for measurements.\n",
    "        pred_lens (np.ndarray): shape=(n, 3). Predicted measurement values [LVPW, LVID, IVS]\n",
    "        sys_i (array-like): indices predicted to be end systole\n",
    "        dia_i (array-like): indices predicted to be end diastole\n",
    "        figsize (tuple, optional): plt figure size. Defaults to (12, 12).\n",
    "        units (str, optional): Units to show on plot. Defaults to 'PX'.\n",
    "        fps (int, optional): Frame rate so save animation in. Defaults to 50.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure Path object\n",
    "    if isinstance(save_path, str):\n",
    "        save_path = Path(save_path)\n",
    "    \n",
    "    # Setup figure layout and static plot\n",
    "    grid = plt.GridSpec(4, 1)\n",
    "    fig = plt.figure(0, figsize=figsize)\n",
    "    ax1 = fig.add_subplot(grid[3:, 0])\n",
    "    ax2 = fig.add_subplot(grid[:3, 0])\n",
    "    for l, n in zip(pred_lens.T, ['LVPW', 'LVID', 'IVS']):\n",
    "        ax1.plot(l, label=n)\n",
    "    l1, = ax1.plot([0, 0, 0], pred_lens[0], 'ro')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel('Frame')\n",
    "    ax1.set_ylabel(f'Measurement [{units}]')\n",
    "    ax1.vlines(sys_i, pred_lens.min(), pred_lens.max(), linestyles='dashed', colors='b', label='Systole')\n",
    "    ax1.vlines(dia_i, pred_lens.min(), pred_lens.max(), linestyles='dashed', colors='g', label='Diastole')\n",
    "    im = ax2.imshow(overlay_preds(preds[0], clip[0] / 255))\n",
    "    l2, = ax2.plot(*pred_pts[0].T, 'C1o-')\n",
    "    ax2.set_title(save_path.name)\n",
    "\n",
    "    # Modifies plot for each frame of animation\n",
    "    def animate(i):\n",
    "        im.set_data(overlay_preds(preds[i], clip[i] / 255))\n",
    "        l1.set_data([i, i , i], pred_lens[i])\n",
    "        l2.set_data(*pred_pts[i].T)\n",
    "\n",
    "    # Save animation\n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(clip), interval=1000 / fps)\n",
    "    writer = animation.FFMpegWriter(fps)\n",
    "    ani.save(save_path, writer)\n",
    "\n",
    "    del fig\n",
    "\n",
    "def make_plot(\n",
    "            save_path: Union[Path, str], title: str, pred_lens: np.ndarray, \n",
    "            sys_i, dia_i, figsize=(8, 6)\n",
    "        ) -> None:\n",
    "    \"\"\"Save a plot showing measurement values over time.\n",
    "\n",
    "    Args:\n",
    "        save_path (Union[Path, str]): .png path to save plot to.\n",
    "        title (str): Plot title.\n",
    "        pred_lens (np.ndarray): shape=(n, 3). Predicted measurements [LVPW, LVID, IVS]\n",
    "        sys_i (array-like): indices predicted to be end systole\n",
    "        dia_i (array-like): indices predicted to be end diastole\n",
    "        figsize (tuple, optional): plt figure size. Defaults to (8, 6).\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(1, figsize=figsize)\n",
    "    plt.clf()\n",
    "    for l, n in zip(pred_lens.T, ['LVPW', 'LVID', 'IVS']):\n",
    "        plt.plot(l, label=n)\n",
    "    plt.plot(sys_i, pred_lens[sys_i], 'r+')\n",
    "    plt.plot(dia_i, pred_lens[dia_i], 'rx')\n",
    "    plt.plot([], [], 'rx', label='Diastole')\n",
    "    plt.plot([], [], 'r+', label='Systole')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Measurement [px]')\n",
    "    plt.legend()\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "\n",
    "def make_animation_cv2(\n",
    "            save_path: Union[Path, str], clip: np.ndarray, preds: np.ndarray, pred_pts: np.ndarray, \n",
    "            fps=30.0, line_color=(1, 1, 0), point_color=(1, 0.5, 0), linewidth=2, markersize=4\n",
    "        ) -> None:\n",
    "    \"\"\"Creates an animation with predictions overlayed on top of the clip.\n",
    "\n",
    "    Args:\n",
    "        save_path (Union[Path, str]): .avi path to save animation to.\n",
    "        clip (np.ndarray): shape=(n, h, w, 3). Input video used for inference.\n",
    "        preds (np.ndarray): shape=(n, h, w, 4). Raw model predictions.\n",
    "        pred_pts (np.ndarray): shape=(n, 4, 2). Predicted points for measurements.\n",
    "        fps (float, optional): Animation frame rate. Defaults to 30.0.\n",
    "        line_color (tuple, optional): Color of measurement lines. Defaults to (1, 1, 0).\n",
    "        point_color (tuple, optional): Color of measurement endpoints. Defaults to (1, 0.5, 0).\n",
    "        linewidth (int, optional): Width of measurement lines. Defaults to 2.\n",
    "        markersize (int, optional): Size of measurement endpoints. Defaults to 4.\n",
    "    \"\"\"\n",
    "    out = cv2.VideoWriter(str(save_path), cv2.VideoWriter_fourcc(*'MJPG'), fps, (clip.shape[2], clip.shape[1]))\n",
    "    for frame, pred, line in zip(clip, preds, pred_pts):\n",
    "        \n",
    "        # Overlay raw predictions\n",
    "        img = overlay_preds(pred, frame / 255)\n",
    "        if not np.isnan(line).any():\n",
    "            line = line.round().astype(int)\n",
    "        \n",
    "            # Draw measurement\n",
    "            for pt0, pt1 in zip(line[:-1], line[1:]):\n",
    "                img = cv2.line(img, tuple(pt0), tuple(pt1), line_color, linewidth)\n",
    "            for pt in line:\n",
    "                img = cv2.circle(img, tuple(pt), radius=markersize, color=point_color, thickness=-1)\n",
    "        \n",
    "        # Write to file\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        out.write(img[:, :, ::-1])\n",
    "    \n",
    "    # Close file\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2654db29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print((clips['/athena/sablab/scratch/prj4005/lvhSubset/0XFCE9C3251F3E58A9.avi'][1].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7537ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preds(Path('/athena/sablab/scratch/prj4005/Echonet/lvh/Inference'),'0XFCE9C3251F3E58A9.avi',\n",
    "           clips['/athena/sablab/scratch/prj4005/lvhSubset/0XFCE9C3251F3E58A9.avi'][0][:,:,:,:],\n",
    "           clips['/athena/sablab/scratch/prj4005/lvhSubset/0XFCE9C3251F3E58A9.avi'][1][:,:,:,:],csv=True, avi=False, plot=False,npy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183162c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c473eaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 10 19:17:58 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  A40                 On   | 00000000:65:00.0 Off |                    0 |\r\n",
      "|  0%   31C    P0    77W / 300W |   1826MiB / 45634MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     54866      C   ...a/envs/echo/bin/python3.9     1823MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83642d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a2850bf18e0794739cd05d473d4a4c1d773f8ed487374071186bc3930ebae7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
